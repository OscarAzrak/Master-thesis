{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from func import *\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\master3\\Master-thesis\\Files\\func.py:21: DtypeWarning: Columns (15,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_read = pd.read_csv(filename, sep=seperator)\n"
     ]
    }
   ],
   "source": [
    "filename = 'all_data_anonymized.csv'\n",
    "date_col = 'todate'\n",
    "start_date = '1980-01-01'\n",
    "seperator = ';'\n",
    "fill = 0\n",
    "lim = 5\n",
    "df_read = load_and_preprocess_data(filename, date_col, start_date, seperator, fill, lim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [5, 10, 20, 40, 60, 100, 180, 240, 360, 480]\n",
    "window_m = [10, 30, 60, 100, 180]\n",
    "assets = df_read.columns\n",
    "df_feat = add_features(df_read, window_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_days = 9\n",
    "\n",
    "return_column_shift = 'avgreturn'\n",
    "volatility_column_shift = 'volatility'\n",
    "df = add_y_col(df_feat, df_read, date_col, target_days, return_column_shift, volatility_column_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, X_test, y_train, y_eval, y_test, X_train_eval, y_train_eval = prepare_training_dataset(df, date_col, shuffle=False, train_split=0.25, eval_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 10.0}\n",
      "Best accuracy on evaluation set: 0.5086063469241039\n"
     ]
    }
   ],
   "source": [
    "param_grid_alpha = {'alpha': [0.1, 1.0, 10.0]}\n",
    "ridge_best, grid_search = optimize_and_train_ridge(X_train, y_train, X_train_eval, y_train_eval, param_grid_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oscar Azrak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_best, best_params = optimize_and_train_xgb(X_train, y_train, X_eval, y_eval, param_grid_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 47869, number of negative: 49501\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.008679 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8670\n",
      "[LightGBM] [Info] Number of data points in the train set: 97370, number of used features: 34\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491620 -> initscore=-0.033525\n",
      "[LightGBM] [Info] Start training from score -0.033525\n",
      "Best hyperparameters: {'learning_rate': 0.01, 'max_depth': 10, 'n_estimators': 200, 'num_leaves': 31}\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] Number of positive: 95752, number of negative: 98988\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.017170 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 8670\n",
      "[LightGBM] [Info] Number of data points in the train set: 194740, number of used features: 34\n",
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "[LightGBM] [Info] [binary:BoostFromScore]: pavg=0.491691 -> initscore=-0.033237\n",
      "[LightGBM] [Info] Start training from score -0.033237\n"
     ]
    }
   ],
   "source": [
    "\n",
    "param_grid_lgb = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 63, 127, 255]\n",
    "}\n",
    "\n",
    "# Call the function with your datasets and hyperparameter grid\n",
    "lgb_best, best_params = optimize_and_train_lgb(X_train, y_train, X_eval, y_eval, param_grid_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Oscar Azrak\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\core\\dense.py:88: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 705us/step - accuracy: 0.5193 - loss: 0.2496 - val_accuracy: 0.5444 - val_loss: 0.2475\n",
      "Epoch 2/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 676us/step - accuracy: 0.5342 - loss: 0.2483 - val_accuracy: 0.5472 - val_loss: 0.2471\n",
      "Epoch 3/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 666us/step - accuracy: 0.5428 - loss: 0.2474 - val_accuracy: 0.5519 - val_loss: 0.2462\n",
      "Epoch 4/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 698us/step - accuracy: 0.5434 - loss: 0.2470 - val_accuracy: 0.5520 - val_loss: 0.2461\n",
      "Epoch 5/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 666us/step - accuracy: 0.5495 - loss: 0.2461 - val_accuracy: 0.5590 - val_loss: 0.2451\n",
      "Epoch 6/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 686us/step - accuracy: 0.5542 - loss: 0.2454 - val_accuracy: 0.5621 - val_loss: 0.2442\n",
      "Epoch 7/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 686us/step - accuracy: 0.5573 - loss: 0.2448 - val_accuracy: 0.5649 - val_loss: 0.2433\n",
      "Epoch 8/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 668us/step - accuracy: 0.5630 - loss: 0.2438 - val_accuracy: 0.5655 - val_loss: 0.2431\n",
      "Epoch 9/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 667us/step - accuracy: 0.5664 - loss: 0.2432 - val_accuracy: 0.5680 - val_loss: 0.2432\n",
      "Epoch 10/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 671us/step - accuracy: 0.5708 - loss: 0.2421 - val_accuracy: 0.5709 - val_loss: 0.2415\n",
      "Epoch 11/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 683us/step - accuracy: 0.5724 - loss: 0.2414 - val_accuracy: 0.5753 - val_loss: 0.2409\n",
      "Epoch 12/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 671us/step - accuracy: 0.5753 - loss: 0.2407 - val_accuracy: 0.5775 - val_loss: 0.2403\n",
      "Epoch 13/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 666us/step - accuracy: 0.5781 - loss: 0.2404 - val_accuracy: 0.5807 - val_loss: 0.2397\n",
      "Epoch 14/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 662us/step - accuracy: 0.5788 - loss: 0.2397 - val_accuracy: 0.5796 - val_loss: 0.2398\n",
      "Epoch 15/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 672us/step - accuracy: 0.5796 - loss: 0.2393 - val_accuracy: 0.5862 - val_loss: 0.2384\n",
      "Epoch 16/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 666us/step - accuracy: 0.5857 - loss: 0.2385 - val_accuracy: 0.5886 - val_loss: 0.2379\n",
      "Epoch 17/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 683us/step - accuracy: 0.5868 - loss: 0.2382 - val_accuracy: 0.5908 - val_loss: 0.2372\n",
      "Epoch 18/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 670us/step - accuracy: 0.5895 - loss: 0.2372 - val_accuracy: 0.5924 - val_loss: 0.2364\n",
      "Epoch 19/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 674us/step - accuracy: 0.5926 - loss: 0.2365 - val_accuracy: 0.5917 - val_loss: 0.2368\n",
      "Epoch 20/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 683us/step - accuracy: 0.5937 - loss: 0.2362 - val_accuracy: 0.5965 - val_loss: 0.2357\n",
      "Epoch 21/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685us/step - accuracy: 0.5945 - loss: 0.2356 - val_accuracy: 0.5992 - val_loss: 0.2346\n",
      "Epoch 22/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 688us/step - accuracy: 0.5982 - loss: 0.2350 - val_accuracy: 0.5986 - val_loss: 0.2348\n",
      "Epoch 23/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 692us/step - accuracy: 0.6000 - loss: 0.2346 - val_accuracy: 0.6019 - val_loss: 0.2340\n",
      "Epoch 24/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 659us/step - accuracy: 0.6010 - loss: 0.2340 - val_accuracy: 0.6027 - val_loss: 0.2334\n",
      "Epoch 25/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685us/step - accuracy: 0.6016 - loss: 0.2337 - val_accuracy: 0.6008 - val_loss: 0.2339\n",
      "Epoch 26/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 677us/step - accuracy: 0.6026 - loss: 0.2332 - val_accuracy: 0.6058 - val_loss: 0.2330\n",
      "Epoch 27/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 670us/step - accuracy: 0.6033 - loss: 0.2330 - val_accuracy: 0.6028 - val_loss: 0.2342\n",
      "Epoch 28/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 671us/step - accuracy: 0.6042 - loss: 0.2328 - val_accuracy: 0.6079 - val_loss: 0.2324\n",
      "Epoch 29/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 675us/step - accuracy: 0.6066 - loss: 0.2323 - val_accuracy: 0.6057 - val_loss: 0.2328\n",
      "Epoch 30/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 681us/step - accuracy: 0.6075 - loss: 0.2318 - val_accuracy: 0.6107 - val_loss: 0.2312\n",
      "Epoch 31/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 671us/step - accuracy: 0.6073 - loss: 0.2319 - val_accuracy: 0.6086 - val_loss: 0.2316\n",
      "Epoch 32/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 687us/step - accuracy: 0.6063 - loss: 0.2319 - val_accuracy: 0.6085 - val_loss: 0.2316\n",
      "Epoch 33/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 694us/step - accuracy: 0.6118 - loss: 0.2305 - val_accuracy: 0.6092 - val_loss: 0.2310\n",
      "Epoch 34/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 676us/step - accuracy: 0.6071 - loss: 0.2319 - val_accuracy: 0.6121 - val_loss: 0.2312\n",
      "Epoch 35/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 677us/step - accuracy: 0.6121 - loss: 0.2306 - val_accuracy: 0.6147 - val_loss: 0.2307\n",
      "Epoch 36/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 686us/step - accuracy: 0.6116 - loss: 0.2301 - val_accuracy: 0.6135 - val_loss: 0.2307\n",
      "Epoch 37/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 676us/step - accuracy: 0.6152 - loss: 0.2299 - val_accuracy: 0.6136 - val_loss: 0.2298\n",
      "Epoch 38/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685us/step - accuracy: 0.6123 - loss: 0.2303 - val_accuracy: 0.6110 - val_loss: 0.2313\n",
      "Epoch 39/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 686us/step - accuracy: 0.6124 - loss: 0.2304 - val_accuracy: 0.6126 - val_loss: 0.2304\n",
      "Epoch 40/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 671us/step - accuracy: 0.6144 - loss: 0.2298 - val_accuracy: 0.6150 - val_loss: 0.2297\n",
      "Epoch 41/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 676us/step - accuracy: 0.6154 - loss: 0.2292 - val_accuracy: 0.6203 - val_loss: 0.2282\n",
      "Epoch 42/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 685us/step - accuracy: 0.6154 - loss: 0.2294 - val_accuracy: 0.6174 - val_loss: 0.2292\n",
      "Epoch 43/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 670us/step - accuracy: 0.6189 - loss: 0.2284 - val_accuracy: 0.6140 - val_loss: 0.2300\n",
      "Epoch 44/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 688us/step - accuracy: 0.6191 - loss: 0.2280 - val_accuracy: 0.6168 - val_loss: 0.2291\n",
      "Epoch 45/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 669us/step - accuracy: 0.6196 - loss: 0.2284 - val_accuracy: 0.6180 - val_loss: 0.2284\n",
      "Epoch 46/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 683us/step - accuracy: 0.6205 - loss: 0.2280 - val_accuracy: 0.6222 - val_loss: 0.2278\n",
      "Epoch 47/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 660us/step - accuracy: 0.6191 - loss: 0.2282 - val_accuracy: 0.6195 - val_loss: 0.2280\n",
      "Epoch 48/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 673us/step - accuracy: 0.6199 - loss: 0.2275 - val_accuracy: 0.6232 - val_loss: 0.2276\n",
      "Epoch 49/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 668us/step - accuracy: 0.6213 - loss: 0.2276 - val_accuracy: 0.6215 - val_loss: 0.2275\n",
      "Epoch 50/50\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 677us/step - accuracy: 0.6207 - loss: 0.2270 - val_accuracy: 0.6203 - val_loss: 0.2279\n"
     ]
    }
   ],
   "source": [
    "NN_model, history, X_test_scaled = train_and_evaluate_NN(X_train_eval, y_train_eval, X_eval, y_eval, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "Ridge Classifier:\n",
      "Accuracy: 0.5281781630148452\n",
      "Confusion Matrix:\n",
      "[[70783 28420]\n",
      " [63464 32076]]\n",
      "Precision: 0.5302168738428987\n",
      "Recall: 0.33573372409462005\n",
      "F1 Score: 0.41113589171729603\n",
      "MSE: 0.4718218369851548\n",
      "RMSE: 0.6868928861075465\n",
      "\n",
      "\n",
      "XGBoost Classifier:\n",
      "Accuracy: 0.5266325362143954\n",
      "Confusion Matrix:\n",
      "[[58120 41083]\n",
      " [51102 44438]]\n",
      "Precision: 0.5196150653055974\n",
      "Recall: 0.46512455516014234\n",
      "F1 Score: 0.490862195613633\n",
      "MSE: 0.4733674637856046\n",
      "RMSE: 0.6880170519584559\n",
      "\n",
      "\n",
      "LightGBM Classifier:\n",
      "Accuracy: 0.5251279891960173\n",
      "Confusion Matrix:\n",
      "[[59317 39886]\n",
      " [52592 42948]]\n",
      "Precision: 0.5184827486297897\n",
      "Recall: 0.4495289930918987\n",
      "F1 Score: 0.48155000168185946\n",
      "MSE: 0.47487201080398267\n",
      "RMSE: 0.6891095782268468\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Store predictions in a dictionary\n",
    "predictions = {\n",
    "    \"Ridge Classifier\": ridge_best.predict(X_test),\n",
    "    \"XGBoost Classifier\": xgb_best.predict(X_test),\n",
    "    \"LightGBM Classifier\": lgb_best.predict(X_test),\n",
    "}   \n",
    "\n",
    "# Iterate through the dictionary and evaluate each model\n",
    "for model_name, y_pred in predictions.items():\n",
    "    print(model_name + \":\")\n",
    "    evaluate_model_performance(y_test, y_pred)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Accuracy may be bad since you didn't explicitly set num_leaves OR 2^max_depth > num_leaves. (num_leaves=31).\n",
      "LightGBM Classifier Prediction Scores: [0.52707745 0.53107638 0.42127966 ... 0.54653081 0.48889907 0.50623161]\n",
      "XGBoost Classifier Prediction Scores: [0.5330586  0.54325885 0.42294225 ... 0.52330583 0.4944392  0.46730632]\n",
      "Ridge Classifier Prediction Scores: [0.50229653 0.50292907 0.48869302 ... 0.50448351 0.49014079 0.47994537]\n",
      "\u001b[1m6086/6086\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 406us/step\n",
      "NN Classifier Prediction Scores: [[0.5182142 ]\n",
      " [0.74977434]\n",
      " [0.2878918 ]\n",
      " ...\n",
      " [0.36692137]\n",
      " [0.73923874]\n",
      " [0.7057015 ]]\n"
     ]
    }
   ],
   "source": [
    "# lgb score predict\n",
    "y_pred_prob_lgb = lgb_best.predict_proba(X_test)[:, 1]  # Get probability of class 1\n",
    "print(\"LightGBM Classifier Prediction Scores:\", y_pred_prob_lgb)\n",
    "\n",
    "y_pred_prob_xgb = xgb_best.predict_proba(X_test)[:, 1]  # Get probability of class 1\n",
    "print(\"XGBoost Classifier Prediction Scores:\", y_pred_prob_xgb)\n",
    "\n",
    "y_scores = ridge_best.decision_function(X_test)\n",
    "y_pred_prob_ridge = sigmoid(y_scores)  # Convert scores to probabilities using sigmoid\n",
    "print(\"Ridge Classifier Prediction Scores:\", y_pred_prob_ridge)\n",
    "\n",
    "y_pred_prob_NN = NN_model.predict(X_test_scaled)  # Get probability of class 1\n",
    "print(\"NN Classifier Prediction Scores:\", y_pred_prob_NN)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test['lgb'] = y_pred_prob_lgb\n",
    "X_test['xgb'] = y_pred_prob_xgb\n",
    "X_test['ridge'] = y_pred_prob_ridge\n",
    "X_test['NN'] = y_pred_prob_NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['VaR_10', 'VaR_100', 'VaR_180', 'VaR_30', 'VaR_60', 'avgreturn_10',\n",
      "       'avgreturn_100', 'avgreturn_180', 'avgreturn_30', 'avgreturn_60',\n",
      "       'momentum_10', 'momentum_100', 'momentum_180', 'momentum_30',\n",
      "       'momentum_60', 'skew_10', 'skew_100', 'skew_180', 'skew_30', 'skew_60',\n",
      "       'volatility_10', 'volatility_100', 'volatility_180', 'volatility_30',\n",
      "       'volatility_60', 'MACRO_8', 'MACRO_0', 'MACRO_1', 'MACRO_2', 'MACRO_3',\n",
      "       'MACRO_4', 'MACRO_5', 'MACRO_6', 'MACRO_7', 'lgb', 'xgb', 'ridge',\n",
      "       'NN'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(X_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# top 10 best and worst assets for each class and only keep asset column\n",
    "\n",
    "top_10_best_assets_lgb = X_test.sort_values(by='lgb', ascending=False).head(10)\n",
    "top_10_worst_assets_lgb = X_test.sort_values(by='lgb', ascending=True).head(10)\n",
    "\n",
    "top_10_best_assets_xgb = X_test.sort_values(by='xgb', ascending=False).head(10)\n",
    "top_10_worst_assets_xgb = X_test.sort_values(by='xgb', ascending=True).head(10)\n",
    "\n",
    "top_10_best_assets_ridge = X_test.sort_values(by='ridge', ascending=False).head(10)\n",
    "top_10_worst_assets_ridge = X_test.sort_values(by='ridge', ascending=True).head(10)\n",
    "\n",
    "top_10_best_assets_NN = X_test.sort_values(by='NN', ascending=False).head(10)\n",
    "top_10_worst_assets_NN = X_test.sort_values(by='NN', ascending=True).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 best assets for LightGBM Classifier:\n",
      "Index([425846, 425672, 425498, 425556, 425614, 425730, 425788, 418107, 418165,\n",
      "       418223],\n",
      "      dtype='int64')\n",
      "\n",
      "\n",
      "Top 10 worst assets for LightGBM Classifier:\n",
      "Index([425785, 425959, 425843, 426133, 425901, 426017, 461778, 461604, 373092,\n",
      "       425321],\n",
      "      dtype='int64')\n",
      "\n",
      "\n",
      "Top 10 best assets for XGBoost Classifier:\n",
      "Index([332212, 332270, 332328, 434318, 434260, 434376, 434202, 332386, 361143,\n",
      "       332444],\n",
      "      dtype='int64')\n",
      "\n",
      "\n",
      "Top 10 worst assets for XGBoost Classifier:\n",
      "Index([416824, 416534, 416708, 416592, 416766, 417172, 416882, 416940, 416650,\n",
      "       461662],\n",
      "      dtype='int64')\n",
      "\n",
      "\n",
      "Top 10 best assets for Ridge Classifier:\n",
      "Index([488762, 460001, 459943, 488704, 490386, 488646, 490444, 458957, 488530,\n",
      "       460175],\n",
      "      dtype='int64')\n",
      "\n",
      "\n",
      "Top 10 worst assets for Ridge Classifier:\n",
      "Index([458203, 458261, 458319, 458087, 458145, 487950, 459569, 459566, 459565,\n",
      "       459578],\n",
      "      dtype='int64')\n",
      "\n",
      "\n",
      "Top 10 best assets for NN Classifier:\n",
      "Index([490444, 490328, 490386, 490270, 490212, 490096, 490038, 490154, 330882,\n",
      "       490560],\n",
      "      dtype='int64')\n",
      "\n",
      "\n",
      "Top 10 worst assets for NN Classifier:\n",
      "Index([470281, 470629, 470571, 470919, 470339, 470687, 470861, 470397, 470513,\n",
      "       470745],\n",
      "      dtype='int64')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# print the assets\n",
    "\n",
    "print(\"Top 10 best assets for LightGBM Classifier:\")\n",
    "print(top_10_best_assets_lgb.index)\n",
    "print(\"\\n\")\n",
    "print(\"Top 10 worst assets for LightGBM Classifier:\")\n",
    "print(top_10_worst_assets_lgb.index)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Top 10 best assets for XGBoost Classifier:\")\n",
    "print(top_10_best_assets_xgb.index)\n",
    "print(\"\\n\")\n",
    "print(\"Top 10 worst assets for XGBoost Classifier:\")\n",
    "print(top_10_worst_assets_xgb.index)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Top 10 best assets for Ridge Classifier:\")\n",
    "print(top_10_best_assets_ridge.index)\n",
    "print(\"\\n\")\n",
    "print(\"Top 10 worst assets for Ridge Classifier:\")\n",
    "print(top_10_worst_assets_ridge.index)\n",
    "print(\"\\n\")\n",
    "\n",
    "print(\"Top 10 best assets for NN Classifier:\")\n",
    "print(top_10_best_assets_NN.index)\n",
    "print(\"\\n\")\n",
    "print(\"Top 10 worst assets for NN Classifier:\")\n",
    "print(top_10_worst_assets_NN.index)\n",
    "print(\"\\n\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
