{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from func import *\n",
    "import pandas as pd\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\osaz001\\Master-thesis\\Files\\func.py:21: DtypeWarning: Columns (15,27) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df_read = pd.read_csv(filename, sep=seperator)\n"
     ]
    }
   ],
   "source": [
    "filename = 'all_data_anonymized.csv'\n",
    "date_col = 'todate'\n",
    "start_date = '1980-01-01'\n",
    "seperator = ';'\n",
    "fill = 0\n",
    "lim = 5\n",
    "df_read = load_and_preprocess_data(filename, date_col, start_date, seperator, fill, lim)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "windows = [5, 10, 20, 40, 60, 100, 180, 240, 360, 480]\n",
    "window_m = [10, 30, 60, 100, 180]\n",
    "assets = df_read.columns\n",
    "df_feat = add_features(df_read, window_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_days = 9\n",
    "\n",
    "return_column_shift = 'avgreturn'\n",
    "volatility_column_shift = 'volatility'\n",
    "df = add_y_col(df_feat, df_read, date_col, target_days, return_column_shift, volatility_column_shift)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_eval, X_test, y_train, y_eval, y_test, X_train_eval, y_train_eval = prepare_training_dataset(df, date_col, shuffle=False, train_split=0.25, eval_split=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best parameters: {'alpha': 10.0}\n",
      "Best accuracy on evaluation set: 0.5086063469241039\n"
     ]
    }
   ],
   "source": [
    "param_grid_alpha = {'alpha': [0.1, 1.0, 10.0]}\n",
    "ridge_best, grid_search = optimize_and_train_ridge(X_train, y_train, X_train_eval, y_train_eval, param_grid_alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\appl\\Anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:889: UserWarning: `early_stopping_rounds` in `fit` method is deprecated for better compatibility with scikit-learn, use `early_stopping_rounds` in constructor or`set_params` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "param_grid_xgb = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "xgb_best, best_params = optimize_and_train_xgb(X_train, y_train, X_eval, y_eval, param_grid_xgb)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid_lgb = {\n",
    "    'max_depth': [3, 6, 10],\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'num_leaves': [31, 63, 127, 255]\n",
    "}\n",
    "\n",
    "# Call the function with your datasets and hyperparameter grid\n",
    "lgb_best, best_params = optimize_and_train_lgb(X_train, y_train, X_eval, y_eval, param_grid_lgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NN_model, history, X_test_scaled = train_and_evaluate_NN(X_train_eval, y_train_eval, X_eval, y_eval, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Store predictions in a dictionary\n",
    "predictions = {\n",
    "    \"Ridge Classifier\": ridge_best.predict(X_test),\n",
    "    \"XGBoost Classifier\": xgb_best.predict(X_test),\n",
    "    \"LightGBM Classifier\": lgb_best.predict(X_test),\n",
    "}   \n",
    "\n",
    "# Iterate through the dictionary and evaluate each model\n",
    "for model_name, y_pred in predictions.items():\n",
    "    print(model_name + \":\")\n",
    "    evaluate_model_performance(y_test, y_pred)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "models = {\n",
    "    'xgb': xgb_best,\n",
    "    'ridge': ridge_best\n",
    "}\n",
    "\n",
    "# Dictionary to hold the results\n",
    "results_best = {}\n",
    "results_worst = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    results_best[name], results_worst[name] = predict_and_analyze_ext(model, X_test, df, name) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep same index from X_test in df as new df\n",
    "\n",
    "df_2 = df.loc[X_test.index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>todate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>120284</th>\n",
       "      <td>1997-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120285</th>\n",
       "      <td>1997-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120286</th>\n",
       "      <td>1997-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120287</th>\n",
       "      <td>1997-07-25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120288</th>\n",
       "      <td>1997-07-25</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           todate\n",
       "120284 1997-07-25\n",
       "120285 1997-07-25\n",
       "120286 1997-07-25\n",
       "120287 1997-07-25\n",
       "120288 1997-07-25"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dddddd = df[['todate']]\n",
    "dddddd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Use the dates in df_2 to filter rows in df_read\n",
    "df_2_read = df_read.loc[df_2[date_col].unique()]\n",
    "\n",
    "# fill missing values with 0\n",
    "df_2_read.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df_2_neutral = df_2_read.copy()\n",
    "\n",
    "for col in df_2_neutral.columns:\n",
    "    df_2_neutral[col] = 0  \n",
    "\n",
    "\n",
    "model_dfs = {\n",
    "    'xgb': df_2_neutral.copy(),\n",
    "    'ridge': df_2_neutral.copy()\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\osaz001\\Master-thesis\\Files\\Codes.ipynb Cell 16\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/osaz001/Master-thesis/Files/Codes.ipynb#X55sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m a\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\appl\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:420: UserWarning: X does not have valid feature names, but RidgeClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected 2D array, got 1D array instead:\narray=[-6.88621300e-03 -1.32046382e-02 -1.55207620e-02 -6.89701700e-03\n -1.54267930e-02  1.60888967e-03  8.54843907e-04  4.50969017e-04\n  1.05358157e-03 -3.10840138e-04  1.44800070e-02  8.29198590e-02\n  7.89195780e-02  2.95002840e-02 -1.80287280e-02 -4.03750512e-01\n -4.18091379e-01 -6.57602500e-01  3.63896731e-01 -3.52495334e-01\n  6.00431533e-03  8.22148406e-03  9.06711178e-03  5.64395053e-03\n  8.83360659e-03 -4.19803530e-02 -3.69427000e-03  1.02978780e-02\n  4.23327600e-03 -8.69978500e-03 -2.72703880e-02  3.85981530e-02\n -8.30574100e-03  2.40736000e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\osaz001\\Master-thesis\\Files\\Codes.ipynb Cell 17\u001b[0m line \u001b[0;36m1\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/osaz001/Master-thesis/Files/Codes.ipynb#X56sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m ridge_best\u001b[39m.\u001b[39;49mpredict(X_test\u001b[39m.\u001b[39;49miloc[\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[1;32mc:\\appl\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_ridge.py:1212\u001b[0m, in \u001b[0;36m_RidgeClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m   1210\u001b[0m     scores \u001b[39m=\u001b[39m \u001b[39m2\u001b[39m \u001b[39m*\u001b[39m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdecision_function(X) \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m   1211\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_label_binarizer\u001b[39m.\u001b[39minverse_transform(scores)\n\u001b[1;32m-> 1212\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mpredict(X)\n",
      "File \u001b[1;32mc:\\appl\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:419\u001b[0m, in \u001b[0;36mLinearClassifierMixin.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    406\u001b[0m \u001b[39mPredict class labels for samples in X.\u001b[39;00m\n\u001b[0;32m    407\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m \u001b[39m    Vector containing the class labels for each sample.\u001b[39;00m\n\u001b[0;32m    417\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    418\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 419\u001b[0m scores \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdecision_function(X)\n\u001b[0;32m    420\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(scores\u001b[39m.\u001b[39mshape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[0;32m    421\u001b[0m     indices \u001b[39m=\u001b[39m xp\u001b[39m.\u001b[39mastype(scores \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m, \u001b[39mint\u001b[39m)\n",
      "File \u001b[1;32mc:\\appl\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_base.py:400\u001b[0m, in \u001b[0;36mLinearClassifierMixin.decision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    397\u001b[0m check_is_fitted(\u001b[39mself\u001b[39m)\n\u001b[0;32m    398\u001b[0m xp, _ \u001b[39m=\u001b[39m get_namespace(X)\n\u001b[1;32m--> 400\u001b[0m X \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_data(X, accept_sparse\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mcsr\u001b[39;49m\u001b[39m\"\u001b[39;49m, reset\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)\n\u001b[0;32m    401\u001b[0m scores \u001b[39m=\u001b[39m safe_sparse_dot(X, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcoef_\u001b[39m.\u001b[39mT, dense_output\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mintercept_\n\u001b[0;32m    402\u001b[0m \u001b[39mreturn\u001b[39;00m xp\u001b[39m.\u001b[39mreshape(scores, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m) \u001b[39mif\u001b[39;00m scores\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39melse\u001b[39;00m scores\n",
      "File \u001b[1;32mc:\\appl\\Anaconda3\\lib\\site-packages\\sklearn\\base.py:546\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    544\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mValidation should be done on X, y or both.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    545\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m no_val_y:\n\u001b[1;32m--> 546\u001b[0m     X \u001b[39m=\u001b[39m check_array(X, input_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mX\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mcheck_params)\n\u001b[0;32m    547\u001b[0m     out \u001b[39m=\u001b[39m X\n\u001b[0;32m    548\u001b[0m \u001b[39melif\u001b[39;00m no_val_X \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[1;32mc:\\appl\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:902\u001b[0m, in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator, input_name)\u001b[0m\n\u001b[0;32m    900\u001b[0m     \u001b[39m# If input is 1D raise error\u001b[39;00m\n\u001b[0;32m    901\u001b[0m     \u001b[39mif\u001b[39;00m array\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m--> 902\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    903\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mExpected 2D array, got 1D array instead:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39marray=\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[0;32m    904\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mReshape your data either using array.reshape(-1, 1) if \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    905\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39myour data has a single feature or array.reshape(1, -1) \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    906\u001b[0m             \u001b[39m\"\u001b[39m\u001b[39mif it contains a single sample.\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(array)\n\u001b[0;32m    907\u001b[0m         )\n\u001b[0;32m    909\u001b[0m \u001b[39mif\u001b[39;00m dtype_numeric \u001b[39mand\u001b[39;00m array\u001b[39m.\u001b[39mdtype\u001b[39m.\u001b[39mkind \u001b[39min\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mUSV\u001b[39m\u001b[39m\"\u001b[39m:\n\u001b[0;32m    910\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m    911\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mdtype=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mnumeric\u001b[39m\u001b[39m'\u001b[39m\u001b[39m is not compatible with arrays of bytes/strings.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    912\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mConvert your data to numeric values explicitly instead.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    913\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Expected 2D array, got 1D array instead:\narray=[-6.88621300e-03 -1.32046382e-02 -1.55207620e-02 -6.89701700e-03\n -1.54267930e-02  1.60888967e-03  8.54843907e-04  4.50969017e-04\n  1.05358157e-03 -3.10840138e-04  1.44800070e-02  8.29198590e-02\n  7.89195780e-02  2.95002840e-02 -1.80287280e-02 -4.03750512e-01\n -4.18091379e-01 -6.57602500e-01  3.63896731e-01 -3.52495334e-01\n  6.00431533e-03  8.22148406e-03  9.06711178e-03  5.64395053e-03\n  8.83360659e-03 -4.19803530e-02 -3.69427000e-03  1.02978780e-02\n  4.23327600e-03 -8.69978500e-03 -2.72703880e-02  3.85981530e-02\n -8.30574100e-03  2.40736000e-02].\nReshape your data either using array.reshape(-1, 1) if your data has a single feature or array.reshape(1, -1) if it contains a single sample."
     ]
    }
   ],
   "source": [
    "ridge_best.predict(X_test.iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_df_with_asset_performance(df, portfolios, value):\n",
    "    \"\"\" Update df by marking assets in portfolios with a specified value. \"\"\"\n",
    "    for date, assets in portfolios.items():\n",
    "        for asset in assets:\n",
    "            if asset in df.columns: \n",
    "                df.at[pd.to_datetime(date), asset] = value\n",
    "\n",
    "\n",
    "# Gather all best and worst assets for each date for each model\n",
    "portfolios_best = { 'lgb': {}, 'xgb': {}, 'ridge': {} }\n",
    "portfolios_worst = { 'lgb': {}, 'xgb': {}, 'ridge': {} }\n",
    "\n",
    "for name, model in models.items():\n",
    "    best_assets, worst_assets = predict_and_analyze_ext(model, X_test, df, name) \n",
    "\n",
    "    # Accumulate best and worst assets for each date\n",
    "    for date in best_assets['todate'].unique():\n",
    "        portfolios_best[name].setdefault(date, []).extend(best_assets[best_assets['todate'] == date]['asset'].tolist())\n",
    "        portfolios_worst[name].setdefault(date, []).extend(worst_assets[worst_assets['todate'] == date]['asset'].tolist())\n",
    "\n",
    "    update_df_with_asset_performance(model_dfs[name], portfolios_best[name], 1)\n",
    "    update_df_with_asset_performance(model_dfs[name], portfolios_worst[name], -1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = model_dfs['ridge']\n",
    "\n",
    "\n",
    "b = df_2_read\n",
    "\n",
    "ab = a*b\n",
    "#np.dot(a,b).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>VaR_10</th>\n",
       "      <th>VaR_100</th>\n",
       "      <th>VaR_180</th>\n",
       "      <th>VaR_30</th>\n",
       "      <th>VaR_60</th>\n",
       "      <th>avgreturn_10</th>\n",
       "      <th>avgreturn_100</th>\n",
       "      <th>avgreturn_180</th>\n",
       "      <th>avgreturn_30</th>\n",
       "      <th>avgreturn_60</th>\n",
       "      <th>momentum_10</th>\n",
       "      <th>momentum_100</th>\n",
       "      <th>momentum_180</th>\n",
       "      <th>momentum_30</th>\n",
       "      <th>momentum_60</th>\n",
       "      <th>skew_10</th>\n",
       "      <th>skew_100</th>\n",
       "      <th>skew_180</th>\n",
       "      <th>skew_30</th>\n",
       "      <th>skew_60</th>\n",
       "      <th>volatility_10</th>\n",
       "      <th>volatility_100</th>\n",
       "      <th>volatility_180</th>\n",
       "      <th>volatility_30</th>\n",
       "      <th>volatility_60</th>\n",
       "      <th>MACRO_8</th>\n",
       "      <th>MACRO_0</th>\n",
       "      <th>MACRO_1</th>\n",
       "      <th>MACRO_2</th>\n",
       "      <th>MACRO_3</th>\n",
       "      <th>MACRO_4</th>\n",
       "      <th>MACRO_5</th>\n",
       "      <th>MACRO_6</th>\n",
       "      <th>MACRO_7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>319106</th>\n",
       "      <td>-0.009637</td>\n",
       "      <td>-0.012813</td>\n",
       "      <td>-0.015318</td>\n",
       "      <td>-0.013930</td>\n",
       "      <td>-0.015276</td>\n",
       "      <td>0.002830</td>\n",
       "      <td>0.000745</td>\n",
       "      <td>0.000412</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.000077</td>\n",
       "      <td>0.025472</td>\n",
       "      <td>0.072294</td>\n",
       "      <td>0.072128</td>\n",
       "      <td>0.002162</td>\n",
       "      <td>0.004485</td>\n",
       "      <td>-0.356854</td>\n",
       "      <td>-0.108553</td>\n",
       "      <td>-0.083858</td>\n",
       "      <td>-0.253355</td>\n",
       "      <td>-0.009850</td>\n",
       "      <td>0.009225</td>\n",
       "      <td>0.008473</td>\n",
       "      <td>0.009310</td>\n",
       "      <td>0.008648</td>\n",
       "      <td>0.009055</td>\n",
       "      <td>-0.04198</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>-0.02727</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>-0.008306</td>\n",
       "      <td>0.024074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319107</th>\n",
       "      <td>-0.006886</td>\n",
       "      <td>-0.013205</td>\n",
       "      <td>-0.015521</td>\n",
       "      <td>-0.006897</td>\n",
       "      <td>-0.015427</td>\n",
       "      <td>0.001609</td>\n",
       "      <td>0.000855</td>\n",
       "      <td>0.000451</td>\n",
       "      <td>0.001054</td>\n",
       "      <td>-0.000311</td>\n",
       "      <td>0.014480</td>\n",
       "      <td>0.082920</td>\n",
       "      <td>0.078920</td>\n",
       "      <td>0.029500</td>\n",
       "      <td>-0.018029</td>\n",
       "      <td>-0.403751</td>\n",
       "      <td>-0.418091</td>\n",
       "      <td>-0.657603</td>\n",
       "      <td>0.363897</td>\n",
       "      <td>-0.352495</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.008221</td>\n",
       "      <td>0.009067</td>\n",
       "      <td>0.005644</td>\n",
       "      <td>0.008834</td>\n",
       "      <td>-0.04198</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>-0.02727</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>-0.008306</td>\n",
       "      <td>0.024074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319108</th>\n",
       "      <td>-0.018143</td>\n",
       "      <td>-0.011536</td>\n",
       "      <td>-0.012432</td>\n",
       "      <td>-0.015143</td>\n",
       "      <td>-0.013968</td>\n",
       "      <td>-0.001752</td>\n",
       "      <td>0.000752</td>\n",
       "      <td>0.000646</td>\n",
       "      <td>0.001086</td>\n",
       "      <td>-0.000156</td>\n",
       "      <td>-0.015770</td>\n",
       "      <td>0.072918</td>\n",
       "      <td>0.113009</td>\n",
       "      <td>0.030418</td>\n",
       "      <td>-0.009030</td>\n",
       "      <td>-0.652002</td>\n",
       "      <td>-0.272680</td>\n",
       "      <td>-0.287846</td>\n",
       "      <td>-0.548325</td>\n",
       "      <td>-0.145080</td>\n",
       "      <td>0.010819</td>\n",
       "      <td>0.007315</td>\n",
       "      <td>0.007044</td>\n",
       "      <td>0.008381</td>\n",
       "      <td>0.008065</td>\n",
       "      <td>-0.04198</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>-0.02727</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>-0.008306</td>\n",
       "      <td>0.024074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319109</th>\n",
       "      <td>-0.007447</td>\n",
       "      <td>-0.010656</td>\n",
       "      <td>-0.012399</td>\n",
       "      <td>-0.007459</td>\n",
       "      <td>-0.011743</td>\n",
       "      <td>0.002182</td>\n",
       "      <td>0.000705</td>\n",
       "      <td>0.000522</td>\n",
       "      <td>0.001350</td>\n",
       "      <td>0.000189</td>\n",
       "      <td>0.019640</td>\n",
       "      <td>0.068421</td>\n",
       "      <td>0.091412</td>\n",
       "      <td>0.037794</td>\n",
       "      <td>0.010947</td>\n",
       "      <td>-0.182817</td>\n",
       "      <td>-0.279285</td>\n",
       "      <td>-0.489138</td>\n",
       "      <td>-0.317276</td>\n",
       "      <td>-0.186464</td>\n",
       "      <td>0.007347</td>\n",
       "      <td>0.006080</td>\n",
       "      <td>0.008297</td>\n",
       "      <td>0.006239</td>\n",
       "      <td>0.006732</td>\n",
       "      <td>-0.04198</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>-0.02727</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>-0.008306</td>\n",
       "      <td>0.024074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319110</th>\n",
       "      <td>-0.002923</td>\n",
       "      <td>-0.009040</td>\n",
       "      <td>-0.012328</td>\n",
       "      <td>-0.009508</td>\n",
       "      <td>-0.010451</td>\n",
       "      <td>0.000889</td>\n",
       "      <td>0.000460</td>\n",
       "      <td>0.000198</td>\n",
       "      <td>0.000520</td>\n",
       "      <td>0.000273</td>\n",
       "      <td>0.008005</td>\n",
       "      <td>0.044612</td>\n",
       "      <td>0.034735</td>\n",
       "      <td>0.014567</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>1.003276</td>\n",
       "      <td>-0.563710</td>\n",
       "      <td>-0.376788</td>\n",
       "      <td>-0.842795</td>\n",
       "      <td>-0.864175</td>\n",
       "      <td>0.003390</td>\n",
       "      <td>0.005434</td>\n",
       "      <td>0.007714</td>\n",
       "      <td>0.004763</td>\n",
       "      <td>0.005482</td>\n",
       "      <td>-0.04198</td>\n",
       "      <td>-0.003694</td>\n",
       "      <td>0.010298</td>\n",
       "      <td>0.004233</td>\n",
       "      <td>-0.0087</td>\n",
       "      <td>-0.02727</td>\n",
       "      <td>0.038598</td>\n",
       "      <td>-0.008306</td>\n",
       "      <td>0.024074</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          VaR_10   VaR_100   VaR_180    VaR_30    VaR_60  avgreturn_10  \\\n",
       "319106 -0.009637 -0.012813 -0.015318 -0.013930 -0.015276      0.002830   \n",
       "319107 -0.006886 -0.013205 -0.015521 -0.006897 -0.015427      0.001609   \n",
       "319108 -0.018143 -0.011536 -0.012432 -0.015143 -0.013968     -0.001752   \n",
       "319109 -0.007447 -0.010656 -0.012399 -0.007459 -0.011743      0.002182   \n",
       "319110 -0.002923 -0.009040 -0.012328 -0.009508 -0.010451      0.000889   \n",
       "\n",
       "        avgreturn_100  avgreturn_180  avgreturn_30  avgreturn_60  momentum_10  \\\n",
       "319106       0.000745       0.000412      0.000077      0.000077     0.025472   \n",
       "319107       0.000855       0.000451      0.001054     -0.000311     0.014480   \n",
       "319108       0.000752       0.000646      0.001086     -0.000156    -0.015770   \n",
       "319109       0.000705       0.000522      0.001350      0.000189     0.019640   \n",
       "319110       0.000460       0.000198      0.000520      0.000273     0.008005   \n",
       "\n",
       "        momentum_100  momentum_180  momentum_30  momentum_60   skew_10  \\\n",
       "319106      0.072294      0.072128     0.002162     0.004485 -0.356854   \n",
       "319107      0.082920      0.078920     0.029500    -0.018029 -0.403751   \n",
       "319108      0.072918      0.113009     0.030418    -0.009030 -0.652002   \n",
       "319109      0.068421      0.091412     0.037794     0.010947 -0.182817   \n",
       "319110      0.044612      0.034735     0.014567     0.015806  1.003276   \n",
       "\n",
       "        skew_100  skew_180   skew_30   skew_60  volatility_10  volatility_100  \\\n",
       "319106 -0.108553 -0.083858 -0.253355 -0.009850       0.009225        0.008473   \n",
       "319107 -0.418091 -0.657603  0.363897 -0.352495       0.006004        0.008221   \n",
       "319108 -0.272680 -0.287846 -0.548325 -0.145080       0.010819        0.007315   \n",
       "319109 -0.279285 -0.489138 -0.317276 -0.186464       0.007347        0.006080   \n",
       "319110 -0.563710 -0.376788 -0.842795 -0.864175       0.003390        0.005434   \n",
       "\n",
       "        volatility_180  volatility_30  volatility_60  MACRO_8   MACRO_0  \\\n",
       "319106        0.009310       0.008648       0.009055 -0.04198 -0.003694   \n",
       "319107        0.009067       0.005644       0.008834 -0.04198 -0.003694   \n",
       "319108        0.007044       0.008381       0.008065 -0.04198 -0.003694   \n",
       "319109        0.008297       0.006239       0.006732 -0.04198 -0.003694   \n",
       "319110        0.007714       0.004763       0.005482 -0.04198 -0.003694   \n",
       "\n",
       "         MACRO_1   MACRO_2  MACRO_3  MACRO_4   MACRO_5   MACRO_6   MACRO_7  \n",
       "319106  0.010298  0.004233  -0.0087 -0.02727  0.038598 -0.008306  0.024074  \n",
       "319107  0.010298  0.004233  -0.0087 -0.02727  0.038598 -0.008306  0.024074  \n",
       "319108  0.010298  0.004233  -0.0087 -0.02727  0.038598 -0.008306  0.024074  \n",
       "319109  0.010298  0.004233  -0.0087 -0.02727  0.038598 -0.008306  0.024074  \n",
       "319110  0.010298  0.004233  -0.0087 -0.02727  0.038598 -0.008306  0.024074  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sum the returns across all assets for each day to get the daily total return\n",
    "daily_total_returns = ab.sum(axis=1)\n",
    "cumulative_total_returns = daily_total_returns.cumsum()\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the cumulative total returns\n",
    "cumulative_total_returns.plot(figsize=(10, 6), title='Cumulative Total Returns Over Time')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Cumulative Returns')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cumulative_total_returns[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot daily total returns\n",
    "plt.figure(figsize=(14, 7))\n",
    "plt.subplot(1, 2, 1)\n",
    "daily_total_returns.plot(title='Daily Total Returns')\n",
    "plt.ylabel('Daily Return')\n",
    "\n",
    "# Plot cumulative return\n",
    "plt.subplot(1, 2, 2)\n",
    "cumulative_returns = (1 + daily_total_returns).cumprod() - 1\n",
    "cumulative_returns.plot(title='Cumulative Return')\n",
    "plt.ylabel('Cumulative Return')\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_returns = {}\n",
    "\n",
    "for model, df_indicator in model_dfs.items():\n",
    "    # Multiplying indicator DataFrame with returns DataFrame\n",
    "    weighted_returns = df_indicator * df_2_read\n",
    "    \n",
    "    # Store the weighted returns DataFrame\n",
    "    model_returns[model] = weighted_returns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
